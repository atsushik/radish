#!/bin/bash
# vim: set ft=sh ff=unix expandtab ts=2 sw=2 ar :

set -e
_d() { [ -n "$DEBUG" ]; }
_d && set -x # debug

# radiko xml filter

# config
OUTPUT_DELIMITER=${OUTPUT_DELIMITER:-$'\t'}

SCRIPT_PATH=$(realpath "$0")
SCRIPT_NAME=$(basename "$SCRIPT_PATH")
XML_DIR="$HOME/.config/$SCRIPT_NAME"
FLAT_BASENAME="flat.tsv"
DATA_BASENAME="data.tsv"

DATA_FILE="$XML_DIR/$DATA_BASENAME"
EXPIRATION_TIME=$((3600 * 6)) # sec: check for DATA_FILE

# xml download directory
[ -d "$XML_DIR" ] || mkdir -p "$XML_DIR"

_usage() {
  cat <<... >&2
usage: ${0##*/} [-d|-t] [-k] [GREP_OPT]
       ${0##*/} [-r|-h]

  GREP_OPT
          search keyword (if not specified, output all programs)
  -d, --detag
          remove HTML tags in info field (default)
  -t, --tag
          remain HTML tags in info field
  -k, --key-value
          output key-value format
  -r, --refresh
          force refresh xml file
  -h, --help
          show this message

...
}

awkt() {
  awk -F '\t' -v OFS='\t' "$@"
}

# 全放送局の一週間ぶんの番組情報のxmlファイルをダウンロード
_download_xml() {
  workdir="${1:?_download_xml: need workdir(\$1)}"

  station_url=http://radiko.jp/v3/station/region/full.xml
  base_url=http://radiko.jp/v3/program/station/weekly/
  full_xml="$workdir/full"

  # 放送局一覧を取得後、放送局毎にダウンロード
  : "start: download xml"
  curl -sSL -o "$full_xml" "$station_url"
  xmlstarlet sel --net -t -m '//station' -v id -n <"$full_xml" |
    xargs -P4 -I@ curl -sSL -o "$workdir/@.xml" "${base_url}@.xml"
  # ダウンロード失敗があれば中断
  n_size_zero="$(find "$workdir" -name "*.xml" -size 0 | wc -l)"
  if [ "$n_size_zero" -ne 0 ]; then
    echo "ERROR: xml download failed, [$workdir]" >&2
    exit 1
  fi
  : "finish: download xml"

  # ダウンロード済みファイルを整形
  : "start: format xml"
  for xml in "$workdir/"*.xml; do
    <"$xml" tr -d '\t\n' | xmlstarlet fo | sponge "$xml" &
  done
  wait
  : "finish: format xml"
}

_refresh_xml() {
  tmpdir=$(mktemp -d)
  : "$tmpdir"
  _download_xml "$tmpdir"
  _flatten "$tmpdir" |
    tee "${tmpdir}/${FLAT_BASENAME}" |
    _convert_datetime >"${tmpdir}/${DATA_BASENAME}"

  # 所定のディレクトリに格納
  #   ユーザー毎にディレクトリを変える／cronだと$USERが未定義なことを考慮
  backupdir="${TMPDIR:-/tmp}/${SCRIPT_NAME}.${HOME##*/}"
  [ -e "$backupdir" ] && rm -rf "$backupdir"
  : "$(mv -vf "$XML_DIR" "$backupdir" && mv -v "$tmpdir" "$XML_DIR")"
}
# flatファイルの日付曜日フォーマットを変更
# shellcheck disable=SC2016
_convert_datetime() {
  awkt '
    function week(date){
      if (!wk[date]) {
        cmd="LANG=C date -d "date" +%a"
        cmd | getline wk[date]
      }
      return wk[date]
    }
    NR==1{$3="date\tweekday\tftime"; $4="duration"; print}
    NR>1{
      ymd=substr($3, 1, 8)
      wkday=week(ymd)
      ftime=substr($3, 9, 4)
      $3=ymd "\t" wkday "\t" ftime;
      $4=$4/60;
      print
    }
  '
}

_body_filter() {
  # 1行目をそのまま出力
  IFS= read -r header
  printf '%s\n' "$header"

  # 2行目以降に cat または grep を適用
  if [ $# = 0 ]; then
    cat
  else
    grep "$@"
  fi
}

_flatten_header() {
  paste -s <<'...'
station_id
prog_id
prog_ft
prog_dur
title
url
pfm
info
...
}

# カレントディレクトリのxmlに対し、番組データを抽出して出力
#   info, pfm の改行やタブは _download_xml() で除去済み
_flatten() {
  xmldir="${1:?_flatten: need xmldir(\$1)}"

  _flatten_header
  xmlstarlet sel -t -m //prog \
    -v ../../@id -o $'\t' \
    -v @id -o $'\t' \
    -v @ft -o $'\t' \
    -v @dur -o $'\t' \
    -v title -o $'\t' \
    -v url -o $'\t' \
    -v pfm -o $'\t' \
    -v info -n \
    "$xmldir/"*.xml |
    xmlstarlet unesc
}

_search_tag() {
  _body_filter "$@"
}

# shellcheck disable=SC2016
_search_detag() {
  _search_tag "$@" |
    awkt '{
    gsub(/<[^>]+>/, " ", $NF);
    gsub(/  +/, " ", $NF);
    sub(/^ /, "", $NF);
    print;
  }'
}

_convert_key_value() {
  # shellcheck disable=SC2016
  awkt '
    NR==1{for(i=1; i<=NF; i++) h[i]=$i}
    NR>1 {for(i=1; i<=NF; i++) print h[i], $i}
  '
}

# main
output_cmd=_search_detag
unset filter_cmd
parameter=()
for opt in "$@"; do
  case "$opt" in
    -h | --help)
      _usage
      exit
      ;;
    -r | --refresh)
      _refresh_xml
      exit
      ;;
    -t | --tag)
      output_cmd=_search_tag
      ;;
    -d | --detag)
      output_cmd=_search_detag
      ;;
    -k | --key-value)
      filter_cmd=_convert_key_value
      ;;
    *)
      parameter+=("$opt")
      ;;
  esac
done

# データファイル格納ディレクトリを作成
[ -d "$XML_DIR" ] || mkdir -p "$XML_DIR"

# データファイルが無い、または古い場合は作成
if [ ! -f "$DATA_FILE" ] || [ $(($(date +%s) - $(stat -c %Y "$DATA_FILE"))) -ge $EXPIRATION_TIME ]; then
  _refresh_xml
fi

# 検索＆フィルター
if [ -n "$filter_cmd" ]; then
  <"$DATA_FILE" "$output_cmd" "${parameter[@]}" | "$filter_cmd"
else
  <"$DATA_FILE" "$output_cmd" "${parameter[@]}"
fi
